{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y71vns_Kgmns"
   },
   "outputs": [],
   "source": [
    "!pip install mne braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyivKdQjgbak"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIU65S50gbal"
   },
   "outputs": [],
   "source": [
    "# This part is from https://mne.tools/stable/auto_tutorials/machine-learning/plot_sensors_decoding.html \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator, Scaler,\n",
    "                          cross_val_multiscore, LinearModel, get_coef,\n",
    "                          Vectorizer, CSP)\n",
    "\n",
    "data_path = sample.data_path()\n",
    "\n",
    "subjects_dir = data_path + '/subjects'\n",
    "raw_fname = data_path + '/MEG/sample/sample_audvis_raw.fif'\n",
    "tmin, tmax = -0.200, 0.700\n",
    "event_id = {'Auditory/Left': 1, 'Auditory/Right': 2, 'Visual/Left': 3, 'Visual/Right': 4}  # just use two\n",
    "raw = mne.io.read_raw_fif(raw_fname, preload=True)\n",
    "\n",
    "# The subsequent decoding analyses only capture evoked responses, so we can\n",
    "# low-pass the MEG data. Usually a value more like 40 Hz would be used,\n",
    "# but here low-pass at 20 so we can more heavily decimate, and allow\n",
    "# the examlpe to run faster. The 2 Hz high-pass helps improve CSP.\n",
    "raw.filter(2, 40)\n",
    "events = mne.find_events(raw,)\n",
    "\n",
    "# Set up pick list: EEG + MEG - bad channels (modify to your needs)\n",
    "raw.info['bads'] += ['MEG 2443', 'EEG 053']  # bads + 2 more\n",
    "\n",
    "# Read epochs\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n",
    "                    picks=('eeg', 'eog'), baseline=(None, 0.), preload=True,\n",
    "                    reject=dict(eeg=150e-6, eog=150e-6), decim=1)\n",
    "epochs.pick_types(meg=False, eeg=True, exclude='bads')  # remove stim and EOG\n",
    "del raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYEv3Lb3gbam"
   },
   "outputs": [],
   "source": [
    "from braindecode.datasets import create_from_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22ilnjjogbam"
   },
   "outputs": [],
   "source": [
    "sfreq = epochs.info[\"sfreq\"]\n",
    "ch_names = epochs.info[\"ch_names\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slvIFgP8gbao"
   },
   "outputs": [],
   "source": [
    "windows_dataset = create_from_X_y(\n",
    "    X[:, :-1,:],\n",
    "    y,\n",
    "    drop_last_window=False,\n",
    "    sfreq=sfreq,\n",
    "    ch_names=ch_names[:-1],)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZT4BDvc9gbao"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=4\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = windows_dataset[0][0].shape[0]\n",
    "input_window_samples = windows_dataset[0][0].shape[1]\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=input_window_samples,\n",
    "    final_conv_length='auto',\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1WfsBljgbao",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import skorch\n",
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "# These values we found good for shallow network:\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "\n",
    "# For deep4 they should be:\n",
    "# lr = 1 * 0.01\n",
    "# weight_decay = 0.5 * 0.001\n",
    "\n",
    "batch_size = 16\n",
    "n_epochs = 10\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=skorch.dataset.CVSplit(cv=10, stratified=True, random_state=320),  # using valid_set for validation\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "# Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "# in the dataset.\n",
    "clf.fit(windows_dataset, y=y, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFQXRThkgbap"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "# Extract loss and accuracy values for plotting from history object\n",
    "results_columns = ['train_loss', 'valid_loss', 'train_accuracy', 'valid_accuracy']\n",
    "df = pd.DataFrame(clf.history[:, results_columns], columns=results_columns,\n",
    "                  index=clf.history[:, 'epoch'])\n",
    "\n",
    "# get percent of misclass for better visual comparison to loss\n",
    "df = df.assign(train_misclass=100 - 100 * df.train_accuracy,\n",
    "               valid_misclass=100 - 100 * df.valid_accuracy)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "fig, ax1 = plt.subplots(figsize=(8, 3))\n",
    "df.loc[:, ['train_loss', 'valid_loss']].plot(\n",
    "    ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False, fontsize=14)\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\n",
    "ax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "df.loc[:, ['train_misclass', 'valid_misclass']].plot(\n",
    "    ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\n",
    "ax2.set_ylabel(\"Misclassification Rate [%]\", color='tab:red', fontsize=14)\n",
    "ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend\n",
    "ax1.set_xlabel(\"Epoch\", fontsize=14)\n",
    "\n",
    "# where some data has already been plotted to ax\n",
    "handles = []\n",
    "handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\n",
    "handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\n",
    "plt.legend(handles, [h.get_label() for h in handles], fontsize=14)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mne_decoding_DL.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
